{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af3de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset\n",
    "import utility\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from monai.transforms.utils import allow_missing_keys_mode\n",
    "from monai.utils import first\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "from utility import window_center_adjustment, dice_loss, calculate_metrics\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "from dataset import KneeDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.networks.nets.swin_unetr import SwinUNETR\n",
    "from torchvision.ops.focal_loss import sigmoid_focal_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from copy import deepcopy\n",
    "import patchify\n",
    "import shutil\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics.classification import Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71812c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bc138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC\n",
      "FC_crop_resize\n"
     ]
    }
   ],
   "source": [
    "bone_type='FC'\n",
    "run_name = 'FC_crop_resize';\n",
    "start_fold=0\n",
    "print(bone_type)\n",
    "print(run_name)\n",
    "model_path=f'FC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ff6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_path) is False:\n",
    "    os.mkdir(model_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a730df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify_valid_data(valid_imgs, valid_masks, fold):\n",
    "    ret_img = [];\n",
    "    ret_mask = [];\n",
    "\n",
    "\n",
    "    os.makedirs(os.path.join('valid_patches', f'{fold}'));\n",
    "    for img_path, mask_path in tqdm(zip(valid_imgs, valid_masks)):\n",
    "        file_name = os.path.basename(img_path);\n",
    "        file_name = file_name[:file_name.rfind('.')];\n",
    "        img = nib.load(img_path);\n",
    "        mask = nib.load(mask_path);\n",
    "        canonical_mask = nib.as_closest_canonical(mask)\n",
    "        canonical_img = nib.as_closest_canonical(img)\n",
    "        img = canonical_img.get_fdata();\n",
    "        mask = canonical_mask.get_fdata();\n",
    "\n",
    "        #zero-pad image and mask\n",
    "        d,h,w = mask.shape;\n",
    "        new_d = (d%config.CROP_SIZE_D != 0)*(config.CROP_SIZE_D - d%config.CROP_SIZE_D);\n",
    "        new_h = (h%config.CROP_SIZE_H != 0) * (config.CROP_SIZE_H - h%config.CROP_SIZE_H);\n",
    "        new_w = (w%config.CROP_SIZE_L != 0) * (config.CROP_SIZE_L - w%config.CROP_SIZE_L);\n",
    "\n",
    "        padded_img = np.zeros((d+new_d, h+new_h, w+new_w), dtype=img.dtype);\n",
    "        padded_mask = np.zeros((d+new_d, h+new_h, w+new_w), dtype=mask.dtype);\n",
    "\n",
    "        padded_img[:d,:h,:w] = img;\n",
    "        padded_mask[:d,:h,:w] = mask;\n",
    "\n",
    "        img_patches = patchify.patchify(\n",
    "            padded_img,(config.CROP_SIZE_D, config.CROP_SIZE_H, config.CROP_SIZE_L), \n",
    "            (config.CROP_SIZE_D, config.CROP_SIZE_H, config.CROP_SIZE_L));\n",
    "        mask_patches = patchify.patchify(padded_mask,config.CROP_SIZE_D,config.CROP_SIZE_D);\n",
    "        for i in range(img_patches.shape[0]):\n",
    "            for j in range(img_patches.shape[1]):\n",
    "                for k in range(img_patches.shape[2]):\n",
    "                    # for m in range(96):\n",
    "                    #     im = img_patches[i][j][k][m];\n",
    "                    #     ma = mask_patches[i][j][k][m];\n",
    "                    #     im = (((im - np.min(im)) / np.max(im))*255).astype(\"uint8\")\n",
    "                    #     cv2.imshow('img', im);\n",
    "                    #     cv2.imshow('mask', ma*255);\n",
    "                    #     cv2.waitKey();\n",
    "                    pickle.dump(img_patches[i][j][k],\n",
    "                                 open(os.path.join('valid_patches',f'{fold}',f'{file_name}_{i}{j}{k}_img.dmp'), 'wb'));\n",
    "                    pickle.dump(mask_patches[i][j][k],\n",
    "                                 open(os.path.join('valid_patches',f'{fold}',f'{file_name}_{i}{j}{k}_mask.dmp'), 'wb'));\n",
    "                    ret_img.append(os.path.join('valid_patches',f'{fold}',f'{file_name}_{i}{j}{k}_img.dmp'));\n",
    "                    ret_mask.append(os.path.join('valid_patches',f'{fold}',f'{file_name}_{i}{j}{k}_mask.dmp'));\n",
    "    return ret_img, ret_mask;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539886ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_folds():\n",
    "    \n",
    "    img_list = glob(os.path.join('/home', 'peyman.tahghighi', 'img', '*.nii.gz'));\n",
    "    mask_list = [];\n",
    "    img_list_temp = [];\n",
    "    for img_path in tqdm(img_list):\n",
    "        file_name = os.path.basename(img_path);\n",
    "        if os.path.exists(os.path.join('/home', 'peyman.tahghighi', bone_type, file_name)) is True:\n",
    "            mask_list.append(os.path.join('/home', 'peyman.tahghighi', bone_type, file_name));\n",
    "            img_list_temp.append(img_path);\n",
    "    img_list = img_list_temp;\n",
    "    \n",
    "    img_list = np.array(img_list);\n",
    "    mask_list = np.array(mask_list);\n",
    "    print(len(img_list));\n",
    "    print(len(mask_list));\n",
    "    \n",
    "    if os.path.exists(f'valid_patches'):\n",
    "        shutil.rmtree('valid_patches');\n",
    "    \n",
    "    if os.path.exists(model_path+'_folds') is False:\n",
    "        os.mkdir(model_path+'_folds');\n",
    "    kfold = KFold(n_splits=config.FOLDS, random_state=42, shuffle=True);\n",
    "    fold = 0;\n",
    "    for train_indices, valid_indices in kfold.split(img_list):\n",
    "        train_img_list, train_mask_list, valid_img_list, valid_mask_list = img_list[train_indices], mask_list[train_indices], img_list[valid_indices], mask_list[valid_indices];\n",
    "        #valid_img_list, valid_mask_list = patchify_valid_data(valid_img_list, valid_mask_list, fold);\n",
    "        pickle.dump([train_img_list, train_mask_list, valid_img_list, valid_mask_list],open(os.path.join(model_path+'_folds', f'{fold}.dmp'), 'wb'));\n",
    "        fold +=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a188c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(pred, mask):\n",
    "    #print(f'mask count in loss: {torch.sum(mask).item()}');\n",
    "    bce_loss = sigmoid_focal_loss(pred.squeeze(dim=1), mask.float(), reduction=\"mean\");\n",
    "    d_loss = dice_loss(pred, mask, sigmoid=True, arange_logits=True, spatial_dims=3);\n",
    "    return bce_loss + d_loss;\n",
    "\n",
    "def train_one_epoch(epoch, model, optimizer, loader, scaler, dice_calculator):\n",
    "    epoch_loss = [];\n",
    "    epoch_dice = [];\n",
    "\n",
    "    pbar = enumerate(loader);\n",
    "    print(('\\n' + '%10s'*3) %('Epoch', 'Loss', 'Dice'));\n",
    "    pbar = tqdm(pbar, total= len(loader), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "\n",
    "    for batch_idx, (mri, mask) in pbar:\n",
    "        mri, mask = mri.to(config.DEVICE), mask.to(config.DEVICE);\n",
    "\n",
    "        # if config.DBG is True:\n",
    "        #     for j in range(config.BATCH_SIZE):\n",
    "        #         mri_np = mri.detach().cpu().numpy()[j];\n",
    "        #         mask_np = mask.detach().cpu().numpy()[j];\n",
    "        #         mri_np = ((mri_np*0.5 + 0.5)).astype(\"uint8\")\n",
    "\n",
    "        #         for i in range(96):\n",
    "        #             mri_np_s = mri_np[i];\n",
    "        #             mask_np_s = mask_np[i].astype(\"uint8\")*255;\n",
    "        #             b = cv2.addWeighted(mri_np_s, 0.5, mask_np_s, 0.5, 0.0);\n",
    "        #             cv2.imshow('b', b);\n",
    "        #             cv2.imshow('mri', mri_np_s);\n",
    "        #             cv2.imshow('mask', mask_np_s);\n",
    "        #             cv2.waitKey();\n",
    "\n",
    "\n",
    "        #with torch.cuda.amp.autocast_mode.autocast():\n",
    "        pred = model(mri.unsqueeze(dim=1));\n",
    "        loss = loss_func(pred, mask);\n",
    "        loss = loss / config.VIRTUAL_BATCH_SIZE;\n",
    "        pred = torch.sigmoid(pred);\n",
    "        if torch.sum(mask).item() != 0:\n",
    "            dice = dice_calculator(pred.flatten(), mask.squeeze().long().flatten());\n",
    "            epoch_dice.append(dice.item());\n",
    "\n",
    "        scaler.scale(loss).backward();\n",
    "        epoch_loss.append(loss.item());\n",
    "\n",
    "        if ((batch_idx+1) % config.VIRTUAL_BATCH_SIZE == 0) or (batch_idx+1 == len(loader)):\n",
    "            scaler.step(optimizer);\n",
    "            scaler.update();\n",
    "            model.zero_grad(set_to_none = True);\n",
    "\n",
    "\n",
    "        pbar.set_description(('%10s' + '%10.4g'*2) %(epoch, np.mean(epoch_loss), np.mean(epoch_dice)));\n",
    "\n",
    "    return np.mean(epoch_loss), np.mean(epoch_dice);\n",
    "\n",
    "def valid_one_epoch(epoch, model, loader, confusion_matrix_calculator):\n",
    "    epoch_loss = [];\n",
    "    epoch_prec = [];\n",
    "    epoch_rec = [];\n",
    "    epoch_f1 = [];\n",
    "\n",
    "    pbar = enumerate(loader);\n",
    "    print(('\\n' + '%10s'*5) %('Epoch', 'Loss', 'Precision', 'Recal', 'F1'));\n",
    "    pbar = tqdm(pbar, total= len(loader), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    cumulative_cm = None;\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (mri, mask) in pbar:\n",
    "            mri, mask = mri.to(config.DEVICE), mask.to(config.DEVICE)\n",
    "            if config.DBG is True:\n",
    "                for j in range(config.BATCH_SIZE):\n",
    "                    mri_np = mri.detach().cpu().numpy()[j];\n",
    "                    mask_np = mask.detach().cpu().numpy()[j];\n",
    "                    mri_np = ((mri_np*0.5 + 0.5)).astype(\"uint8\")\n",
    "\n",
    "                    for i in range(96):\n",
    "                        mri_np_s = mri_np[i];\n",
    "                        mask_np_s = mask_np[i].astype(\"uint8\")*255;\n",
    "                        b = cv2.addWeighted(mri_np_s, 0.5, mask_np_s, 0.5, 0.0);\n",
    "                        cv2.imshow('b', b);\n",
    "                        cv2.imshow('mri', mri_np_s);\n",
    "                        cv2.imshow('mask', mask_np_s);\n",
    "                        cv2.waitKey();\n",
    "\n",
    "            #with torch.cuda.amp.autocast_mode.autocast():\n",
    "            pred = model(mri.unsqueeze(dim=1));\n",
    "            loss = loss_func(pred, mask);\n",
    "            pred = torch.sigmoid(pred);\n",
    "            pred = pred > 0.5;\n",
    "            loss = loss/config.VIRTUAL_BATCH_SIZE;\n",
    "            \n",
    "            cm = confusion_matrix_calculator(pred.squeeze(dim=1), mask);\n",
    "            if cumulative_cm is None:\n",
    "                cumulative_cm = cm;\n",
    "            else:\n",
    "                cumulative_cm += cm;\n",
    "            \n",
    "            precision, recall, f1 = calculate_metrics(cumulative_cm);\n",
    "\n",
    "           \n",
    "            epoch_loss.append(loss.item());\n",
    "\n",
    "            pbar.set_description(('%10s' + '%10.4g'*4) %(epoch, np.mean(epoch_loss),precision, recall, f1));\n",
    "    precision, recall, f1 = calculate_metrics(cumulative_cm);\n",
    "    return np.mean(epoch_loss), [precision, recall, f1];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a8cfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507/507 [00:00<00:00, 3512.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "store_folds();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaad345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNETR(img_size=(config.CROP_SIZE_D,config.CROP_SIZE_H,config.CROP_SIZE_L), in_channels=1, out_channels=1, feature_size=48);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5425d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('model.pt');\n",
    "pretrain_weights = dict();\n",
    "for k in m.keys():\n",
    "    if k != 'out.conv.conv.weight' and k!= 'out.conv.conv.bias':\n",
    "        pretrain_weights[k] = m[k];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff28233",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_TRAINING = True;\n",
    "if RESUME_TRAINING is True:\n",
    "    checkpoint = torch.load('training_checkpoint.pt', map_location = 'cuda');\n",
    "    start_fold = checkpoint['fold'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be3f6525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++ Starting fold : 4 +++++++++\n",
      "Resuming training from epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/203 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch      Loss      Dice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        59   0.02414    0.9124: 100%|██████████| 203/203 [03:13<00:00,  1.05it/s]\n",
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch      Loss Precision     Recal        F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        59   0.02604    0.8955    0.9102    0.9028: 100%|██████████| 51/51 [00:53<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "for f in range(start_fold,config.FOLDS):\n",
    "    print(f\"+++++++++ Starting fold : {f} +++++++++\")\n",
    "    #initialize model weight, initialize other variables every fold\n",
    "    if RESUME_TRAINING is False:\n",
    "        model.load_state_dict(pretrain_weights, strict=False);\n",
    "    if RESUME_TRAINING is True:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "    model.to(config.DEVICE);\n",
    "    \n",
    "    scaler = torch.cuda.amp.grad_scaler.GradScaler();\n",
    "    optimizer = optim.Adam(model.parameters(), config.LEARNING_RATE);\n",
    "    summary_writer = SummaryWriter(os.path.join(model_path + '_exp', f'_{run_name}', f'_{run_name}_{f}'));\n",
    "    best_loss = 10;\n",
    "    best_metrics = None;\n",
    "    early_stopping = config.EARLY_STOPPING_TOLERANCE;\n",
    "    epoch = 0;\n",
    "    \n",
    "    if RESUME_TRAINING is True:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scaler.load_state_dict(checkpoint['gradscalar_state_dict']);\n",
    "        epoch = checkpoint['epoch'];\n",
    "        best_loss = checkpoint['best_loss'];\n",
    "        early_stopping = checkpoint['ES'];\n",
    "        best_metrics = checkpoint['best_metrics'];\n",
    "        RESUME_TRAINING = False;\n",
    "        print(f'Resuming training from epoch {epoch}')\n",
    "    \n",
    "    confusion_matrix_calculator = ConfusionMatrix(task='binary').to(config.DEVICE);\n",
    "    dice = Dice(num_classes=1).to(config.DEVICE);\n",
    "\n",
    "    #define training and testing dataset\n",
    "    train_img_list, train_mask_list, valid_img_list, valid_mask_list = pickle.load(open(os.path.join(model_path+'_folds', f'{f}.dmp'),'rb'));\n",
    "    kneedataset_valid = KneeDataset(valid_img_list, valid_mask_list, train = False);\n",
    "    kneedataset_train = KneeDataset(train_img_list, train_mask_list);\n",
    "    train_loader = DataLoader(kneedataset_train, num_workers=config.NUM_WORKERS, shuffle = True, batch_size=config.BATCH_SIZE, drop_last=False, pin_memory=True);\n",
    "    valid_loader = DataLoader(kneedataset_valid, num_workers=config.NUM_WORKERS, shuffle = False, batch_size=config.BATCH_SIZE, drop_last=False, pin_memory=True);\n",
    "\n",
    "    \n",
    "    \n",
    "    while(True):\n",
    "        model.train();\n",
    "        loss_train,dice_train = train_one_epoch(epoch, model, optimizer, train_loader, scaler, dice);\n",
    "\n",
    "        model.eval();\n",
    "        loss_valid, valid_metrics = valid_one_epoch(epoch, model, valid_loader, confusion_matrix_calculator)\n",
    "\n",
    "        if loss_valid < best_loss:\n",
    "            #stroe best results so far and reset early stopping tolerance\n",
    "            best_loss = loss_valid;\n",
    "            early_stopping = config.EARLY_STOPPING_TOLERANCE;\n",
    "            best_metrics = valid_metrics;\n",
    "            # model_path=f'/home/reza.kakavand/model_3D_Unet/{bone_type}/{run_name}/'\n",
    "            model_save=f'best_model_fold: {f}.ckpt'\n",
    "            pickle.dump(model.state_dict, open(model_path+model_save, 'wb'));\n",
    "            print('New best model found!');\n",
    "        else:\n",
    "            early_stopping -=1;\n",
    "\n",
    "        if early_stopping <= 0:\n",
    "            break;\n",
    "\n",
    "        epoch += 1;\n",
    "        summary_writer.add_scalar('train/loss', loss_train, epoch);\n",
    "        summary_writer.add_scalar('train/dice', dice_train, epoch);\n",
    "        summary_writer.add_scalar('valid/f1', valid_metrics[2], epoch);\n",
    "        \n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'gradscalar_state_dict': scaler.state_dict(),\n",
    "                'fold': f,\n",
    "                'best_loss': best_loss,\n",
    "                'ES': early_stopping,\n",
    "                'best_metrics': best_metrics\n",
    "            },\n",
    "            f'training_checkpoint.pt'\n",
    "            )\n",
    "    f = open(os.path.join(model_path, f'{f}_results.txt'), 'w');\n",
    "    f.write(model_path+f'Epochs: {epoch}\\tPrecision: {best_metrics[0]}\\tRecall: {best_metrics[1]}\\tF1: {best_metrics[2]}');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca7f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 18 10:06:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:17:00.0 Off |                   On |\n",
      "| N/A   42C    P0    68W / 300W |  24259MiB / 80994MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0    1   0   0  |  24240MiB / 40192MiB | 56      0 |  4   0    2    0    0 |\n",
      "|                  |      3MiB / 65535MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0    1    0    2736239      C   /opt/conda/bin/python           24205MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c40160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch==1.12.1+cu113 in ./.local/lib/python3.8/site-packages (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision==0.13.1+cu113 in ./.local/lib/python3.8/site-packages (0.13.1+cu113)\n",
      "Requirement already satisfied: torchaudio==0.12.1 in ./.local/lib/python3.8/site-packages (0.12.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.8/site-packages (from torch==1.12.1+cu113) (4.3.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from torchvision==0.13.1+cu113) (1.23.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu113) (2.25.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu113) (8.2.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu113) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu113) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu113) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu113) (2021.5.30)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113 --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bca0295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributed.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538c9f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "686188a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31efc2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 18 10:06:43 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:17:00.0 Off |                   On |\n",
      "| N/A   41C    P0    68W / 300W |  24259MiB / 80994MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0    1   0   0  |  24240MiB / 40192MiB | 56      0 |  4   0    2    0    0 |\n",
      "|                  |      3MiB / 65535MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0    1    0    2736239      C   /opt/conda/bin/python           24205MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7ac8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in ./.local/lib/python3.8/site-packages (0.6.1)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install einops --user"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
